---
title: "Introduction to Fluidigr"
author: "Otho Mantegazza"
date: "`r Sys.Date()`"
output:
  knitr:::html_vignette:
    toc: yes
    number_sections: true
    highlight: default
vignette: >
  %\VignetteIndexEntry{Introduction to Fluidigr}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

# Setup

```{r setup, message = FALSE}
library(fluidigr)
library(magrittr)
library(dplyr)
library(stringr)
```

# Simple Workflow

Record the path to your fluidigm CSV data and the name of your reference normalizers.

```{r}
path_to_data <- system.file("extdata", "sample-fluidigm-run.csv",
                            package = "fluidigr",
                            mustWork = TRUE)

normalizers <- c("normalizer1",
                 "normalizer2",
                 "normalizer3")
```


Parse them, normalize them and scale them in a [magrittr](https://magrittr.tidyverse.org/index.html) pipe.

```{r, eval=FALSE}
fluidigm_data <- 
  path_to_data %>%
  read_fluidigm() %>%
  normalize() %>%
  scale_fluidigm()
```

And your data are ready to be plotted in ggplot2.

# Details

## Parse

```{r}
dat <- read_fluidigm(path = path_to_data)
```

### optional - make your data tidy

After you have parsed the data, you can modify them using [dplyr](https://dplyr.tidyverse.org/articles/dplyr.html) as you wish.


Example, remove samples:

Our example dataset contains samples that are dilution used for calibration curves.

```{r}
dat$sample_name %>% unique()
```

Those samples, all have the word "Mix" in their name, and can be removed with:

```{r}
dat <- 
  dat %>%
  filter(!sample_name %>% str_detect("Mix"))
```

One sample "H2O" is a negative control, it also can be removed:

```{r}
dat <- 
  dat %>%
  filter(sample_name != "H20")
```

You can check that each sample has been measured the same number of times:

```{r}
dat$sample_name %>% table()
dat$sample_name %>% table() %>% unique()
```

Also, one of the target is a duplicated normalizer. We can remove it with:

```{r}
dat$target_name %>% unique()

dat <- 
  dat %>%
  filter(target_name != "normalizer1bis")
```


## Normalize

You must provided the names of the normalizers exactly as they are stored in the `target_name` column. In this case the name of the normalizers is: `normalizer1`, `normalizer2` and `normalizer3`.

```{r}
normalizers <- c("normalizer1",
                 "normalizer2",
                 "normalizer3")

norm_dat <- 
  dat %>% 
  normalize(normalizers = normalizers) 
```

The `normalize()` function takes the data parsed by `read_fluidigm()` as object and returns the same data with two additional columns:

- `norm_geom_mean` stores the geometric mean of normalizers for each sample.
- `expression` stores the normalized expression values.

Expression values are normalized with the formula: 

$$expression = 2^{-(C_T - C_Tnorm)}$$

Where, for each well, $C_T$ is the recorded threshold cycle (`ct_value`) and $C_Tnorm$ is the geometric mean of the normalizers C~T~ values.

## Scale

Scaling is not necessary, but, together with exploratory plots, it can help you detect patterns in your data.

Fluidgr provides the `scale_fluidigm()` function, that scales expression values with z-score scaling according to the groups provided in the argument `.group`.

This function takes the dataset output of `normalize()` and returns the same dataset with the extra column `scaled_expression`.

```{r}
scaled_dat <- 
  norm_dat %>% 
  scale_fluidigm(.group = target_name)
```

The `scale_fluidigm()` function is a soft wrapper around dplyr's `group_by()` and `mutate()`. If you want to try different scaling methods, you can repliate it's output with:

```{r, eval = FALSE}
norm_dat %>%
  group_by(target_name) %>%
  mutate(scaled_expression = scale(expression))
```

This should provide a good basis and enough freedom to explore and visualize your data as you prefer.

## Visualize

`Fluidi
